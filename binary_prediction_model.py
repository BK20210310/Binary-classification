# -*- coding: utf-8 -*-
"""Binary_prediction_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CYD7xDIDa2LKFAS3cb3eEHUVFCHueUeP

# GPU check
"""

import torch
# Get GPU name, check if it's K80
GPU_name = torch.cuda.get_device_name()
print("Your GPU is {}!".format(GPU_name))

"""# Import packages"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn import metrics, svm, linear_model
import xgboost as xgb
from torchsummary import summary

"""# Data download"""

!gdown --id '1tWjPzb0jBWfXqWMqAwx0ku36PAipSu6f' --output cachexia.csv

df = pd.read_csv('/content/cachexia.csv')
df

"""Descriptive statistics"""

df.loc[0:40,"cachexia"] = "PC"
df.loc[40:97,"cachexia"] = "PC-cachexia"
df

# outlier
print("outlier")
print("IL-6: " + str(df.iloc[18, 4]))
print("CA19-9: " + str(df.iloc[68, 3]))

df.iloc[18, 4] = 0
df.iloc[68, 3] = 0

def BoxPlot(col_name, y_label, pos):
  col_name = str(col_name)
  y_label = str(y_label)
  df_box = df.boxplot(column=col_name,grid=False, by="cachexia", figsize=(2.5,5), widths=0.4, color="black", ax=pos)
  df_box.get_figure().suptitle('')
  df_box.set(xlabel="", ylabel=y_label)
  return df_box

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(13, 15))
BoxPlot("S100A8", "(ng/ml)", axes[0,0])
BoxPlot("S100A9", "(ng/ml)", axes[0,1])
BoxPlot("CA19-9", "", axes[0,2])
BoxPlot("IL-6", "(ng/ml)", axes[1,0])
BoxPlot("TNF_a", "(ng/ml)", axes[1,1])
BoxPlot("Age", "(years)", axes[1,2])
BoxPlot("Body_weight", "(kg)", axes[2,0])
BoxPlot("Body_height", "(cm)", axes[2,1])
BoxPlot("Size", "(cm)", axes[2,2])
plt.savefig("boxplot.png", dpi = 300)

df.loc[0:40,"cachexia"] = 0
df.loc[40:97,"cachexia"] = 1
df.iloc[18, 4] = 6281.6
df.iloc[68, 3] = 352300.0

df = df.iloc[:, 1:17]
print(df)

"""# Neural network"""

df_array = df.to_numpy(dtype = "float32")
df_tensor = torch.from_numpy(df_array)
df_tensor.shape

"""## Data prepare"""

class CachaxiaDataset(Dataset):
  def __init__(self, x):
    self.data = df_tensor[x,0:15]
    self.label = torch.FloatTensor(df_array[:, 15].astype(float))
  
  def __len__(self):
    return len(self.data)
  
  def __getitem__(self, index):

    return self.data[index], self.label[index]

  def shape(self):
    print(self.data.shape)

seed = 22
validation_ratio = 0.49

validation_number = int(len(df_tensor) * validation_ratio)

total_list = range(len(df_tensor))
total_list = np.array(total_list)

np.random.seed(seed)
val_list = np.random.choice(total_list, size = int(validation_number), replace = False)
train_list = np.setdiff1d(total_list, val_list)

print("training sample size = " + str(len(train_list)))
print("training sample list = " + str(train_list))
print()
print("validation sample size = " + str(len(val_list)))
print("validatin sample list = " + str(val_list))

train_set = CachaxiaDataset(train_list)
val_set = CachaxiaDataset(val_list)
train_loader = DataLoader(train_set, batch_size=25, shuffle=True)
val_loader = DataLoader(val_set, batch_size=8, shuffle=False)

train_set.shape()

"""## Create model"""

class NeuralNetwork(nn.Module):
  def __init__(self):
    super(NeuralNetwork, self).__init__()
    self.net = nn.Sequential(
        nn.Linear(15, 24),
        nn.Dropout(0.05),
        nn.BatchNorm1d(24),
        nn.Sigmoid(),
        nn.Linear(24, 6),
        nn.BatchNorm1d(6),
        nn.Sigmoid(),      
        nn.Linear(6, 1),
        nn.Sigmoid()
    )
  
  def forward(self, x):
    return self.net(x).squeeze(1)

"""Set seed"""

def random_seed(seed):
  torch.manual_seed(seed)
  if torch.cuda.is_available():
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)   
  torch.backends.cudnn.benchmark = False
  torch.backends.cudnn.deterministic = True

random_seed(seed)

"""## Training"""

#check device
def get_device():
  return 'cuda' if torch.cuda.is_available() else 'cpu'

device = get_device()
print(f'DEVICE: {device}')

# the path where checkpoint saved
model_path = './model.ckpt'

# create model, define a loss function, and optimizer
model = NeuralNetwork().to(device)
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)

epoch = 2000

best_loss = 9999999

for i in range(epoch):
  train_loss = 0.0
  val_loss = 0.0

  model.train()
  for x, y in train_loader:
    optimizer.zero_grad()
    x, y = x.to(device), y.to(device)
    pred = model(x)
    loss = criterion(pred, y)
    loss.backward()
    optimizer.step()
    train_loss += loss.item()

  model.eval()
  for x, y in val_loader:
    x, y = x.to(device), y.to(device)
    with torch.no_grad():
      output = model(x)
      loss = criterion(output, y)
      val_loss += loss.item()

    if val_loss < best_loss:
      best_loss = val_loss
      torch.save(model.state_dict(), model_path)


  print("epoch = " + str(i+1) + " : training loss = " + str(train_loss) + " and validation loss = " + str(val_loss))

for p in model.parameters():
  print(p)

print(model)

summary(model, (15,))

"""## Prediction"""

train_loader2 = DataLoader(train_set, batch_size=20, shuffle=False)

train_predict = []
validation_predict = []

model.eval()
with torch.no_grad():
  for x, y in train_loader2:
    x, y = x.to(device), y.to(device)
    train_pred = model(x)
    for i in train_pred.cpu().numpy():
      train_predict.append(i)

model.eval()
with torch.no_grad():
  for x, y in val_loader:
    x, y = x.to(device), y.to(device)
    val_pred = model(x)
    for i in val_pred.cpu().numpy():
      validation_predict.append(i)

print("training prediction")
print(train_predict)
print()
print("validation prediction")
print(validation_predict)

"""# SVM"""

# data prepare

train_X = df_array[train_list, 0:15]
train_Y = df_array[train_list, 15]
valid_X = df_array[val_list, 0:15]
valid_Y = df_array[val_list, 15]

# SVM

model_svm = svm.SVC(kernel = 'linear', C = 0.003, probability = True)
model_svm.fit(train_X, train_Y)

train_svm = model_svm.decision_function(train_X)
val_svm = model_svm.decision_function(valid_X)

print("training prediction")
print(train_svm)
print("validation prediction")
print(val_svm)

"""# XGBoost"""

num_round = 31
param = {'max_depth': 3,
         'gamma': 0.15,
         'eta': 0.24,
         'objective': 'binary:logistic',
         "booster" : "gbtree",
         "eval_metric": "auc",
         "subsample" : "0.5",
         "colsample_bytree": "0.6",
         'tree_method': 'exact'}
dtrain = xgb.DMatrix(train_X, train_Y)
dvalid = xgb.DMatrix(valid_X, valid_Y)
evallist = [(dvalid, 'eval'), (dtrain, 'train')]

bst = xgb.train(param, dtrain, num_round, evallist)

train_xgb = bst.predict(dtrain)
val_xgb = bst.predict(dvalid)

print("training prediction")
print(train_xgb)
print("validation prediction")
print(val_xgb)

for tree_i in range(num_round):
  xgb.plot_tree(bst, num_trees=tree_i, label="Tree "+str(tree_i))

"""# ROC curve"""

train_nn = np.array(train_predict)
train_s100a8 = df_array[train_list, 0]
train_s100a9 = df_array[train_list, 1]
train_il6 = df_array[train_list, 3]
train_tnfa = df_array[train_list, 4]
train_label = df_array[train_list, 15]

val_nn = validation_predict
val_s100a8 = df_array[val_list, 0]
val_s100a9 = df_array[val_list, 1]
val_il6 = df_array[val_list, 3]
val_tnfa = df_array[val_list, 4]
val_label = df_array[val_list, 15]

def ROC_curve(model_name, predict_t, predict_v, curve_color, data_state):
  name_dict = {"s100a8": "S100A8", "s100a9": "S100A9", "il6": "IL-6", "tnfa": "TNF-"+chr(945), "nn": "Neural network", "svm": "SVM", "xgb": "XGBoost", "glm": "S100A8+S100A9"}
  model_name = str(model_name)
  curve_color = str(curve_color)

  if data_state == "t":
    fpr_t, tpr_t, thresholds_t = metrics.roc_curve(train_label, predict_t)
    auc_t = metrics.roc_auc_score(train_label, predict_t)
    plot_curve_t = plt.plot(fpr_t, tpr_t, color = curve_color, label = name_dict[model_name] + ", AUC = " + str(round(auc_t, 4)))
    return plot_curve_t
  elif data_state == "v":
    fpr_v, tpr_v, thresholds_v = metrics.roc_curve(val_label, predict_v)
    auc_v = metrics.roc_auc_score(val_label, predict_v)
    plot_curve_v = plt.plot(fpr_v, tpr_v, color = curve_color, label = name_dict[model_name] + ", AUC = " + str(round(auc_v, 4)))
    return plot_curve_v
  else:
    return None

# ROC curve of training data
plt.figure()
#ROC_curve("s100a8", train_s100a8, val_s100a8, "lightblue", "t")
#ROC_curve("s100a9", train_s100a9, val_s100a9, "darkgray", "t")
ROC_curve("nn", train_nn, val_nn, "darkorange", "t")
ROC_curve("svm", train_svm, val_svm, "lightgreen", "t")
ROC_curve("xgb", train_xgb, val_xgb, "red", "t")
plt.plot([0, 1], [0, 1], color='black', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('1 - Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curve of training data')
plt.legend(loc="lower right")
plt.savefig("ROC curve of training data.png", dpi = 300)
plt.show()

# ROC curve of validation data
plt.figure()
#ROC_curve("s100a8", train_s100a8, val_s100a8, "lightblue", "v")
#ROC_curve("s100a9", train_s100a9, val_s100a9, "darkgray", "v")
ROC_curve("nn", train_nn, val_nn, "darkorange", "v")
ROC_curve("svm", train_svm, val_svm, "lightgreen", "v")
ROC_curve("xgb", train_xgb, val_xgb, "red", "v")
plt.plot([0, 1], [0, 1], color='black', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('1 - Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curve of validation data')
plt.legend(loc="lower right")
plt.savefig("ROC curve of validation data.png", dpi = 300)
plt.show()